{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MBTI.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezmnJ_MEco7S"
      },
      "source": [
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxx4C_RdjSLz"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0b6YMmrdDha"
      },
      "source": [
        "# Importing dataset is stored locally\n",
        "df=pd.read_csv('/content/drive/MyDrive/mbti_1.csv', dtype={'type': str, 'posts': str})\n",
        "#df.info()\n",
        "mbti = {'I':'Introversion', 'E':'Extroversion', 'N':'Intuition',\n",
        "        'S':'Sensing', 'T':'Thinking', 'F': 'Feeling',\n",
        "        'J':'Judging', 'P': 'Perceiving'}\n",
        "\n",
        "#TODO: Raus, nur drin um erstmal Zeit zu sparen\n",
        "df = df.head(200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXsq-hHxdFzP"
      },
      "source": [
        "df_counted = df['type'].value_counts()\n",
        "df_counted.head()\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "sns.barplot(x = df_counted.index, y = df_counted.values)\n",
        "plt.ylabel('Number of Occurrences', fontsize=12)\n",
        "plt.xlabel('Types', fontsize=12)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRhd7AVsnZ9t"
      },
      "source": [
        "#Split an ||| \n",
        "df['posts_processed']=df['posts'].apply(lambda x: x.split('|||'))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsSpfjOqdHeT"
      },
      "source": [
        "#Alles zu lower case\n",
        "for posts in df['posts_processed'].items() :\n",
        "    for post in posts[1] : \n",
        "      post = post.lower();\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqSEGIwTstGK"
      },
      "source": [
        "def process_list(posts):\n",
        "  result = []\n",
        "  for post in posts : \n",
        "      result.append(post.lower())\n",
        "      #Von Caro f체r das abk체rzen von loooooove zu loove\n",
        "      #post = ''.join(''.join(s)[:2] for _, s in itertools.groupby(post))\n",
        "  return result\n",
        "\n",
        "df['posts_processed2']=df['posts_processed'].apply(process_list)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CikbeyCldJf6"
      },
      "source": [
        "\n",
        "# Dictionary of English Contractions\n",
        "contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n",
        "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
        "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
        "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
        "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
        "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
        "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
        "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
        "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
        "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
        "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
        "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
        "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
        "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
        "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
        "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
        "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
        "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
        "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
        "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
        "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
        "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
        "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
        "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
        "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
        "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
        "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
        "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
        "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
        "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
        "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
        "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
        "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
        "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
        "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
        "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
        "                     \"you've\": \"you have\"}\n",
        "\n",
        "# Regular expression for finding contractions\n",
        "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
        "\n",
        "# Function for expanding contractions\n",
        "def expand_contractions(text,contractions_dict=contractions_dict):\n",
        "  def replace(match):\n",
        "    return contractions_dict[match.group(0)]\n",
        "  return contractions_re.sub(replace, text)\n",
        "\n",
        "# Expanding Contractions in the reviews\n",
        "df['posts_processed']=df['posts_processed'].apply(lambda x : expand_contractions(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MXD2gY_dLiF"
      },
      "source": [
        "def dequote(s):\n",
        "    \"\"\"\n",
        "    If a string has single or double quotes around it, remove them.\n",
        "    Make sure the pair of quotes match.\n",
        "    If a matching pair of quotes is not found, return the string unchanged.\n",
        "    \"\"\"\n",
        "    if (s[0] == s[-1]) and s.startswith((\"'\", '\"')):\n",
        "        return s[1:-1]\n",
        "    return s\n",
        "\n",
        "#Anf체hrungszeichen entfernen vorne und hinten\n",
        "df['posts_processed'] = df['posts_processed'].apply(dequote)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "071cN0MbdN4g"
      },
      "source": [
        "#Links in den Kommentaren Z채hlen\n",
        "df['links_per_post'] = df['posts_processed'].apply(lambda x: x.count('http')/50)\n",
        "print('Count Links')\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzP-9RNHdPaN"
      },
      "source": [
        "def remove_URL(stringliteral):\n",
        "    \"\"\"Remove URLs from a sample string\"\"\"\n",
        "    return re.sub(r'https?://\\S+', '', str(stringliteral))\n",
        "\n",
        "df['posts_processed']=df['posts_processed'].map(remove_URL)\n",
        "print('Removed Links')\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyu_DFl2dQxK"
      },
      "source": [
        "#Satzzeichen entfernen\n",
        "df['posts_processed']=df['posts_processed'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))\n",
        "print(df.at[0,'posts_processed'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_eg1nC3dSGF"
      },
      "source": [
        "#Zahlen und W철rter mit Zahlen entfernen\n",
        "df['posts_processed']=df['posts_processed'].apply(lambda x: re.sub('\\w*\\d\\w*','', x))\n",
        "print(df.at[0,'posts_processed'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04G8TJ8pdTcX"
      },
      "source": [
        "# Removing extra spaces\n",
        "df['posts_processed']=df['posts_processed'].apply(lambda x: re.sub(' +',' ',x))\n",
        "print('Compare Processing')\n",
        "print('Problem beim Splitten ||| da das wort davor und danach als ein einziges wort betrachtet werden!')\n",
        "print(df.at[0,'posts'])\n",
        "print(df.at[0,'posts_processed'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99Fw1Wb7dU5f"
      },
      "source": [
        "#Durchschnittl. W철rter per Post\n",
        "df['avg_words_per_post'] = df['posts_processed'].apply(lambda x: len(x.split())/50)\n",
        "print('Avg Words per Post')\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdHzlvpZdXRg"
      },
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "sns.swarmplot(\"type\", \"avg_words_per_post\", data=df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGyOPzJodYbv"
      },
      "source": [
        "#Anzahl der Links anzeigen\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.swarmplot(\"type\", \"links_per_post\", data=df)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}